{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib\n",
    "#matplotlib.use('qt5agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "%matplotlib qt5\n",
    "#%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def calibrate(images):\n",
    "    \"\"\"Computes the camera calibration using chessboard images\"\"\"\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "        print(\"processing image: {}\".format(fname))\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "    retval, cameraMatrix, distCoeffs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[0:2], None, None)\n",
    "    return cameraMatrix, distCoeffs\n",
    "\n",
    "\n",
    "def undistort_image(img, mtx, dist):\n",
    "    \"\"\"Apply a distortion correction to raw image\"\"\"\n",
    "    import matplotlib.image as mpimg\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return dst\n",
    "\n",
    "def hls_transform(img):\n",
    "    \"\"\"Applies the hsl transform\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "def sobel_operator(img, dir='x'):\n",
    "    gray = grayscale(img)\n",
    "    if (dir == 'x'):\n",
    "        return cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        return cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    \n",
    "def sobel_scale(img_sobel):\n",
    "    \"\"\"Absolute the derivative to accentuate lines away from horizontal/vertical??\"\"\"\n",
    "    abs_sobel = np.absolute(img_sobel) \n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    return scaled_sobel\n",
    "    \n",
    "def select_yellow(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    lower = np.array([20,60,60])\n",
    "    upper = np.array([38,174, 250])\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    return mask\n",
    "\n",
    "def select_white(img):\n",
    "    lower = np.array([202,202,202])\n",
    "    upper = np.array([255,255,255])\n",
    "    mask = cv2.inRange(img, lower, upper)\n",
    "    return mask\n",
    "\n",
    "def apply_mask(img, mask):\n",
    "    result = cv2.bitwise_and(img,img,mask=mask)\n",
    "    return result                    \n",
    "\n",
    "def threshold_image(img, thresh=(20, 100)):\n",
    "    s_binary = np.zeros_like(img)\n",
    "    s_binary[(img >= thresh[0]) & (img <= thresh[1])] = 1\n",
    "    return s_binary\n",
    "\n",
    "def binary_image_transform_yellow_white_lane_lines(img):\n",
    "    yellow_mask = select_yellow(img)\n",
    "    yellow_image = apply_mask(img, yellow_mask)\n",
    "    ret,yellow_binary = cv2.threshold(grayscale(yellow_image),127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    white_mask = select_white(img)\n",
    "    white_image = apply_mask(img, white_mask)\n",
    "    ret,white_binary = cv2.threshold(grayscale(white_image),127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    combined_binary = np.zeros_like(white_binary)\n",
    "    combined_binary[(yellow_binary > 0) | (white_binary > 0)] = 1\n",
    "#     plot_2_images(img, combined_binary)\n",
    "    return combined_binary\n",
    "\n",
    "def plot_2_images(img1, img2, title1='original',title2='processed'):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(48, 18))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title(title1, fontsize=50)\n",
    "    ax2.imshow(img2, cmap='gray')\n",
    "    ax2.set_title(title2, fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    \n",
    "def plot_image_title(img, title='', text=''):\n",
    "    \n",
    "    font = {'family': 'serif',\n",
    "            'color':  'white',\n",
    "            'weight': 'normal',\n",
    "            'size': 28,\n",
    "            }\n",
    "        \n",
    "    f, ax = plt.subplots(1, 1, figsize=(48, 18))\n",
    "    f.tight_layout()\n",
    "    ax.imshow(img)\n",
    "    plt.text(2, 75.65, text, fontdict=font)\n",
    "    ax.set_title(title, fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "#     plt.savefig(output_file)\n",
    "\n",
    "def binary_image_transform(img):\n",
    "    \"\"\"Uses gradients to create a binary image\"\"\"\n",
    "\n",
    "    # Threshold x gradient\n",
    "    sobel_x = sobel_operator(img, dir='x')\n",
    "    s_x_binary = threshold_image(sobel_scale(sobel_x), thresh=(20, 100))\n",
    "\n",
    "    # Threshold color channel\n",
    "    hls = hls_transform(img)\n",
    "    s_channel = hls[:,:,2]\n",
    "    s_binary = threshold_image(s_channel, thresh=(170, 255))\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(s_x_binary)\n",
    "    combined_binary[(s_binary == 1) | (s_x_binary == 1)] = 1\n",
    "    return combined_binary\n",
    "\n",
    "def unwarp(img, src, dst):\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return warped, M\n",
    "\n",
    "def hist(img):\n",
    "    return np.sum(img[img.shape[0]//2:,:], axis=0)\n",
    "\n",
    "\n",
    "def polyfit(img, y, x, order=2):\n",
    "    \"\"\"Fit polynomial\"\"\"\n",
    "    fit = np.poly1d(np.polyfit(y, x, order))\n",
    "\n",
    "    #y values for plotting\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    fit_x = fit(ploty)\n",
    "    return fit_x\n",
    "\n",
    "\n",
    "def detect_lane_lines(binary_warped, debug = False,nwindows = 9, margin = 100, minpix = 50):\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "\n",
    "    histogram = hist(binary_warped)\n",
    "\n",
    "    out_img = None\n",
    "    if (debug==True):\n",
    "        # For debugging, an output image to visualize the result\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        if (debug==True):\n",
    "            # Draw the windows on the visualization image\n",
    "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "            cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    if (len(rightx)==0 or len(leftx)==0):\n",
    "        return [], [], [], []\n",
    "        \n",
    "#     print(\"len(rightx) {}\".format(len(rightx)))\n",
    "#     print(\"len(leftx) {}\".format(len(leftx)))\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "\n",
    "    left_fitx = polyfit(binary_warped, lefty, leftx, 2)\n",
    "    right_fitx = polyfit(binary_warped, righty, rightx, 2)\n",
    "\n",
    "    if (debug==True):\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "        plt.imshow(out_img)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "    return left_fit, right_fit, left_fitx, right_fitx\n",
    "\n",
    "def detect_lane_lines_subsequent_images(binary_warped, left_fit, right_fit, debug=False, margin = 100):\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    #TODO improve this \n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fitx = polyfit(binary_warped, lefty, leftx, 2)\n",
    "    right_fitx = polyfit(binary_warped, righty, rightx, 2)\n",
    "\n",
    "    \n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "\n",
    "    if (debug==True):\n",
    "        # Create an image to draw on and an image to show the selection window\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "        window_img = np.zeros_like(out_img)\n",
    "        # Color in left and right line pixels\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "        plt.imshow(result)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "        \n",
    "    return left_fit, right_fit, left_fitx, right_fitx\n",
    "\n",
    "        \n",
    "def curvature(binary_warped, left_fitx, right_fitx):    \n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    y_eval = np.max(ploty)\n",
    "\n",
    "    leftx = left_fitx\n",
    "    rightx = right_fitx\n",
    "\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "\n",
    "    # Now our radius of curvature is in meters\n",
    "    center_of_lanes = ((right_fitx[-1] - left_fitx[-1]) //2 + left_fitx[-1]) * xm_per_pix\n",
    "    center_of_car = (binary_warped.shape[1] // 2) * xm_per_pix\n",
    "    return left_curverad, right_curverad, (center_of_lanes - center_of_car)\n",
    "\n",
    "def warp_detected_lines_onto_original(original, warped, left_fitx, right_fitx, Minv):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0] )\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (original.shape[1], original.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(original, 1, newwarp, 0.3, 0)\n",
    "#     plt.imshow(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "cameraMatrix, distCoeffs = calibrate(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a distortion correction to a raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('../test_images/test5.jpg')\n",
    "undist = undistort_image(img, cameraMatrix, distCoeffs)\n",
    "plot_2_images(img, undist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a thresholded binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# binary_image = binary_image_transform(undist)\n",
    "# plot_2_images(img, binary_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_image = binary_image_transform_yellow_white_lane_lines(undist)\n",
    "plot_2_images(undist, binary_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a perspective transform to rectify binary image (\"birds-eye view\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (binary_image.shape[1], binary_image.shape[0])\n",
    "src = np.float32(\n",
    "    [[(img_size[0] / 2) - 55, img_size[1] / 2 + 100],\n",
    "    [((img_size[0] / 6) - 10), img_size[1]],\n",
    "    [(img_size[0] * 5 / 6) + 40, img_size[1]],\n",
    "    [(img_size[0] / 2 + 65), img_size[1] / 2 + 100]])\n",
    "dst = np.float32(\n",
    "    [[(img_size[0] / 4), 0],\n",
    "    [(img_size[0] / 4), img_size[1]],\n",
    "    [(img_size[0] * 3 / 4), img_size[1]],\n",
    "    [(img_size[0] * 3 / 4), 0]])\n",
    "warped, M = unwarp(binary_image, src, dst)\n",
    "Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "print(src)\n",
    "# plot_2_images(undist, warped)\n",
    "\n",
    "warped_undist, M2 = unwarp(undist, src, dst)\n",
    "\n",
    "src2 = np.int32(src.reshape((-1,1,2)))\n",
    "dst2 = np.int32(dst.reshape((-1,1,2)))\n",
    "\n",
    "cv2.polylines(undist,[src2],True,(255,0,0))\n",
    "cv2.polylines(warped_undist,[dst2],True,(255,0,0))\n",
    "\n",
    "plot_2_images(undist, warped_undist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_fit, right_fit, left_fitx, right_fitx = detect_lane_lines(warped, debug=True)\n",
    "left_fit, right_fit, left_fitx, right_fitx = detect_lane_lines_subsequent_images(warped, left_fit, right_fit, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the curvature of the lane and vehicle position with respect to center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_curverad, right_curverad, diff_center = curvature(warped, left_fitx, right_fitx)\n",
    "print(left_curverad, 'm', right_curverad, 'm', diff_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp the detected lane boundaries back onto the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = warp_detected_lines_onto_original(undist, warped, left_fitx, right_fitx, Minv)\n",
    "plot_2_images(img, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# title = \"Radius of curvature = {:f}(m)\\nVehicle is {:f}m {!s} of center \".format(np.mean(left_curverad,right_curverad), np.abs(diff_center), 'left')\n",
    "text = 'Radius of curvature = {:f}(m)\\nVehicle is {:f}m {!s} of center'.format(np.mean([left_curverad,right_curverad]), np.abs(diff_center), 'left' if diff_center > 0 else 'right')\n",
    "plot_image_title(result, '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a class to receive the characteristics of each line detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self):\n",
    "        #loss count\n",
    "        self.loss_count = 0\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = []\n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients of the last n fits of the line\n",
    "        self.recent_fit = []\n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "    #update the stats\n",
    "    def update(self, fit, fitx, radius_of_curvature, line_base_pos, warped):\n",
    "        ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0] )\n",
    "        n = len(self.recent_xfitted)\n",
    "        \n",
    "        if (n > 10):\n",
    "            removed_fitx = self.recent_xfitted.pop(0)\n",
    "            removed_fit = self.recent_fit.pop(0)\n",
    "        \n",
    "        self.recent_xfitted.append(fitx)\n",
    "        self.bestx = np.mean(self.recent_xfitted, axis=0,keepdims=True)\n",
    "        self.recent_fit.append(fit)\n",
    "        self.best_fit = np.mean(self.recent_fit)\n",
    "        self.radius_of_curvature = radius_of_curvature\n",
    "        self.line_base_pos = line_base_pos \n",
    "        self.diffs = self.current_fit - fit\n",
    "        self.current_fit = fit\n",
    "        self.allx = fitx\n",
    "        self.ally = ploty\n",
    "        self.detected = True\n",
    "        self.loss_count = np.max([self.loss_count-1, 0])\n",
    "    def reset():\n",
    "        self.detected = False  \n",
    "        self.recent_xfitted = [] \n",
    "        self.bestx = None     \n",
    "        self.best_fit = None  \n",
    "        self.current_fit = [np.array([False])]  \n",
    "        self.radius_of_curvature = None \n",
    "        self.line_base_pos = None \n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        self.allx = None  \n",
    "        self.ally = None\n",
    "        self.loss_count=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanity_check(leftLine, rightLine, left_fit, right_fit, left_fitx, right_fitx, left_curverad, right_curverad, diff_center):\n",
    "    \n",
    "    #Checking that lines have similar curvature\n",
    "    if ( (left_curverad-right_curverad) / right_curverad > 2):\n",
    "        print(\"left_curverad, right_curverad\")\n",
    "        print(left_curverad, right_curverad)\n",
    "        return False\n",
    "\n",
    "    #Checking that lines are separated by approximately the right distance horizontally\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    if ( ((right_fitx[-1]-left_fitx[-1]) * xm_per_pix - 3.7) > 5e-2):\n",
    "        print(\"right_fitx[-1], left_fitx[-1\")\n",
    "        print(right_fitx[-1], left_fitx[-1])\n",
    "        return False\n",
    "\n",
    "#     #Checking that lines are roughly parallel\n",
    "    upper = right_fitx[0] - left_fitx[0]\n",
    "    lower = right_fitx[-1] - left_fitx[-1]\n",
    "    if ( (upper-lower) / lower > 11e-2):\n",
    "        print(\"upper, lower\")\n",
    "        print(upper, lower)\n",
    "        return False\n",
    "#     print('great, passed sanity checks!')\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanity_check_update_lines(left_fit, right_fit, left_fitx, right_fitx, warped, leftLine, rightLine):\n",
    "    if (len(left_fit) == 0):\n",
    "        leftLine.detected = False\n",
    "        leftLine.loss_count += 1\n",
    "\n",
    "        rightLine.detected = False\n",
    "        rightLine.loss_count += 1\n",
    "\n",
    "        return 0., 0., 0.\n",
    "    left_curverad, right_curverad, diff_center = curvature(warped, left_fitx, right_fitx)\n",
    "\n",
    "    if (sanity_check(leftLine, rightLine, left_fit, right_fit, left_fitx, right_fitx, left_curverad, right_curverad, diff_center)):\n",
    "        leftLine.update(left_fit, left_fitx, left_curverad, diff_center, warped)\n",
    "        rightLine.update(right_fit, right_fitx, right_curverad, diff_center, warped)\n",
    "    else:\n",
    "        leftLine.detected = False\n",
    "        leftLine.loss_count += 1\n",
    "\n",
    "        rightLine.detected = False\n",
    "        rightLine.loss_count += 1\n",
    "        \n",
    "    return left_curverad, right_curverad, diff_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(img, simple=True):\n",
    "    \"\"\"\n",
    "    1) Sanity Check\n",
    "    2) Look-Ahead Filter\n",
    "    3) Reset\n",
    "    4) Smoothing\n",
    "    5) Drawing\n",
    "    \"\"\"\n",
    "    undist = undistort_image(img, cameraMatrix, distCoeffs)\n",
    "    binary_image = binary_image_transform_yellow_white_lane_lines(undist)\n",
    "    warped, M = unwarp(binary_image, src, dst)\n",
    "    \n",
    "    if (simple):\n",
    "        left_fit, right_fit, left_fitx, right_fitx = detect_lane_lines(warped)\n",
    "        left_curverad, right_curverad, diff_center = sanity_check_update_lines(left_fit, right_fit, left_fitx, right_fitx, warped, leftLine, rightLine)\n",
    "    else:    \n",
    "        if (len(leftLine.recent_xfitted) > 0 & leftLine.loss_count < 2 & len(rightLine.recent_xfitted) > 0  & rightLine.loss_count < 5):\n",
    "            left_fit, right_fit, left_fitx, right_fitx = detect_lane_lines_subsequent_images(warped, leftLine.best_fit, rightLine.best_fit)\n",
    "            left_curverad, right_curverad, diff_center = sanity_check_update_lines(left_fit, right_fit, left_fitx, right_fitx, warped, leftLine, rightLine)        \n",
    "        else:\n",
    "            print('resetting....')\n",
    "            leftLine.reset\n",
    "            rightLine.reset\n",
    "            left_fit, right_fit, left_fitx, right_fitx = detect_lane_lines(warped)\n",
    "            left_curverad, right_curverad, diff_center = sanity_check_update_lines(left_fit, right_fit, left_fitx, right_fitx, warped, leftLine, rightLine)\n",
    "        \n",
    "    if (left_curverad == 0. or right_curverad == 0.):\n",
    "        return img\n",
    "    result = warp_detected_lines_onto_original(undist, warped, leftLine.bestx, rightLine.bestx, Minv)\n",
    "    text1 = 'Radius of curvature = {:f}(m)'.format(np.mean([left_curverad,right_curverad]))\n",
    "    text2 = 'Vehicle is {:f}m {!s} of center'.format(np.abs(diff_center), 'left' if diff_center > 0 else 'right')\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(result,text1,(10,50), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(result,text2,(10,95), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test_image_file_names = os.listdir(\"../test_images/\")\n",
    "leftLine = Line()\n",
    "rightLine = Line()\n",
    "for image_file_name in test_image_file_names:\n",
    "    print(image_file_name)\n",
    "    image = mpimg.imread(\"../test_images/\" + image_file_name)    \n",
    "    result = pipeline(image, simple=True)\n",
    "    mpimg.imsave(\"../output_images/\" + image_file_name, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "def process_image(image):\n",
    "    result = pipeline(image)\n",
    "    return result\n",
    "\n",
    "output = '../output_images/project_video.mp4'\n",
    "clip1 = VideoFileClip(\"../project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "def process_image(image):\n",
    "    result = pipeline(image)\n",
    "    return result\n",
    "\n",
    "output = '../output_images/challenge_video.mp4'\n",
    "clip1 = VideoFileClip(\"../challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "def process_image(image):\n",
    "    result = pipeline(image)\n",
    "    return result\n",
    "\n",
    "output = '../output_images/harder_challenge_video.mp4'\n",
    "clip1 = VideoFileClip(\"../harder_challenge_video.mp4\")\n",
    "clip1.set_end(5.23)\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The goals / steps of this project are the following:\n",
    "\n",
    "##Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "\n",
    "##Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector.\n",
    "\n",
    "##Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "\n",
    "##Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "\n",
    "##Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "\n",
    "##Estimate a bounding box for vehicles detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "# Define a function to compute color histogram features \n",
    "# NEED TO CHANGE bins_range if reading .png files with mpimg!\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif color_space == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif color_space == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: feature_image = np.copy(image)      \n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)        \n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features\n",
    "    \n",
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y, \n",
    "# window size (x and y dimensions),  \n",
    "# and overlap fraction (for both x and y)\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            \n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "# Define a function to draw bounding boxes\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajaffer/anaconda/envs/carnd-term1/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "# from lesson_functions import *\n",
    "# NOTE: the next import is only valid for scikit-learn version <= 0.17\n",
    "# for scikit-learn >= 0.18 use:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to extract features from a single image window\n",
    "# This function is very similar to extract_features()\n",
    "# just for a single image rather than list of images\n",
    "def single_img_features(img, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):    \n",
    "    #1) Define an empty list to receive features\n",
    "    img_features = []\n",
    "    #2) Apply color conversion if other than 'RGB'\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(img)      \n",
    "    #3) Compute spatial features if flag is set\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        #4) Append features to list\n",
    "        img_features.append(spatial_features)\n",
    "    #5) Compute histogram features if flag is set\n",
    "    if hist_feat == True:\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        #6) Append features to list\n",
    "        img_features.append(hist_features)\n",
    "    #7) Compute HOG features if flag is set\n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))      \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        #8) Append features to list\n",
    "        img_features.append(hog_features)\n",
    "\n",
    "    #9) Return concatenated array of features\n",
    "    return np.concatenate(img_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 8792 car images\n",
      "read 8968 notcars images\n"
     ]
    }
   ],
   "source": [
    "car_images = glob.glob('../data/vehicles/**/*.png')\n",
    "non_car_images = glob.glob('../data/non-vehicles/**/*.png')\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in car_images:\n",
    "    cars.append(image)\n",
    "for image in non_car_images:\n",
    "    notcars.append(image)\n",
    "\n",
    "print(\"read {} car images\".format(len(cars)))\n",
    "print(\"read {} notcars images\".format(len(notcars)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_space = 'HSV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "# orient = 9  # HOG orientations\n",
    "orient = 12  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "# hog_channel = 0 # Can be 0, 1, 2, or \"ALL\"\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16) # Spatial binning dimensions\n",
    "# hist_bins = 256    # Number of histogram bins\n",
    "hist_bins = 16    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "# y_start_stop = [None, None] # Min and max in y to search in slide_window()\n",
    "y_start_stop = [400, None] # Min and max in y to search in slide_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajaffer/anaconda/envs/carnd-term1/lib/python3.5/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "car_features = extract_features(cars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features(notcars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: 12 orientations 8 pixels per cell and 2 cells per block\n",
      "Feature vector length: 7872\n",
      "5.15 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9899\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "model = svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "\n",
    "\n",
    "# Save to a pickle file.\n",
    "import pickle\n",
    "pickle.dump( model, open( \"model.p\", \"wb\" ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajaffer/anaconda/envs/carnd-term1/lib/python3.5/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model = pickle.load( open( \"model.p\", \"rb\" ) )\n",
    "\n",
    "\n",
    "\n",
    "image = mpimg.imread('../test_images/test1.jpg')\n",
    "draw_image = np.copy(image)\n",
    "\n",
    "# Uncomment the following line if you extracted training\n",
    "# data from .png images (scaled 0 to 1 by mpimg) and the\n",
    "# image you are searching is a .jpg (scaled 0 to 255)\n",
    "# image = image.astype(np.float32)/255\n",
    "\n",
    "windows = slide_window(image, x_start_stop=[None, None], y_start_stop=y_start_stop, \n",
    "                    xy_window=(128, 128), xy_overlap=(0.5, 0.5))\n",
    "\n",
    "hot_windows = search_windows(image, windows, svc, X_scaler, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)                       \n",
    "\n",
    "window_img = draw_boxes(draw_image, hot_windows, color=(0, 0, 255), thick=6)                    \n",
    "\n",
    "# plt.imshow(window_img)\n",
    "plot_2_images(window_img,window_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
